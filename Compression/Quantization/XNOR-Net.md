Cháº¯c cháº¯n rá»“i, Ä‘Ã¢y lÃ  báº£n phÃ¢n tÃ­ch chi tiáº¿t bÃ i bÃ¡o "XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks" dÆ°á»›i gÃ³c nhÃ¬n cá»§a má»™t chuyÃªn gia Ä‘Ã¡nh giÃ¡ cho há»™i nghá»‹ NeurIPS.

***

### **ÄÃ¡nh giÃ¡ BÃ i bÃ¡o: XNOR-Net**

**TÃ³m táº¯t chung:** BÃ i bÃ¡o Ä‘á» xuáº¥t hai phÆ°Æ¡ng phÃ¡p xáº¥p xá»‰ máº¡ng nÆ¡-ron tÃ­ch cháº­p (CNN) nháº±m tÄƒng hiá»‡u quáº£ tÃ­nh toÃ¡n vÃ  tiáº¿t kiá»‡m bá»™ nhá»›: **Binary-Weight-Networks (BWN)** vÃ  **XNOR-Networks (XNOR-Net)**. BWN nhá»‹ phÃ¢n hÃ³a cÃ¡c trá»ng sá»‘, trong khi XNOR-Net nhá»‹ phÃ¢n hÃ³a cáº£ trá»ng sá»‘ vÃ  Ä‘áº§u vÃ o cá»§a cÃ¡c lá»›p tÃ­ch cháº­p. CÃ¡c tÃ¡c giáº£ chá»©ng minh ráº±ng phÆ°Æ¡ng phÃ¡p cá»§a há», Ä‘áº·c biá»‡t lÃ  viá»‡c sá»­ dá»¥ng cÃ¡c há»‡ sá»‘ tá»‰ lá»‡ (scaling factors), giÃºp Ä‘áº¡t Ä‘Æ°á»£c Ä‘á»™ chÃ­nh xÃ¡c cao trÃªn bá»™ dá»¯ liá»‡u quy mÃ´ lá»›n nhÆ° ImageNet, vÆ°á»£t trá»™i Ä‘Ã¡ng ká»ƒ so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p nhá»‹ phÃ¢n hÃ³a trÆ°á»›c Ä‘Ã³.

---

### **Pháº§n A: Bá»‘i cáº£nh vÃ  Sá»± cáº£i tiáº¿n**

#### **1. Káº¿ thá»«a tá»« Ä‘Ã¢u?**

BÃ i bÃ¡o nÃ y xÃ¢y dá»±ng trá»±c tiáº¿p dá»±a trÃªn cÃ¡c cÃ´ng trÃ¬nh tiÃªn phong trong lÄ©nh vá»±c nhá»‹ phÃ¢n hÃ³a máº¡ng nÆ¡-ron. CÃ¡c cÃ´ng trÃ¬nh ná»n táº£ng chÃ­nh bao gá»“m:
* **BinaryConnect (BC)**: ÄÃ¢y lÃ  cÃ´ng trÃ¬nh gáº§n nháº¥t, Ä‘á» xuáº¥t huáº¥n luyá»‡n máº¡ng nÆ¡-ron sÃ¢u vá»›i trá»ng sá»‘ nhá»‹ phÃ¢n trong quÃ¡ trÃ¬nh lan truyá»n xuÃ´i vÃ  ngÆ°á»£c, nhÆ°ng váº«n giá»¯ má»™t báº£n sao trá»ng sá»‘ cÃ³ Ä‘á»™ chÃ­nh xÃ¡c cao (real-valued) Ä‘á»ƒ tÃ­ch lÅ©y cÃ¡c cáº­p nháº­t gradient.
* **BinaryNet (BNN)**: LÃ  má»™t má»Ÿ rá»™ng cá»§a BinaryConnect, BNN tiáº¿n thÃªm má»™t bÆ°á»›c báº±ng cÃ¡ch nhá»‹ phÃ¢n hÃ³a cáº£ trá»ng sá»‘ vÃ  cÃ¡c giÃ¡ trá»‹ kÃ­ch hoáº¡t (activations).
* **Expectation BackPropagation (EBP)**: Má»™t cÃ´ng trÃ¬nh trÆ°á»›c Ä‘Ã³ sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p Bayes biáº¿n phÃ¢n Ä‘á»ƒ suy luáº­n ra cÃ¡c máº¡ng cÃ³ trá»ng sá»‘ vÃ  nÆ¡-ron nhá»‹ phÃ¢n, cho tháº¥y tiá»m nÄƒng Ä‘áº¡t hiá»‡u nÄƒng cao cá»§a máº¡ng nhá»‹ phÃ¢n.

#### **2. Äiá»ƒm yáº¿u cá»§a phÆ°Æ¡ng phÃ¡p cÅ©?**

CÃ¡c phÆ°Æ¡ng phÃ¡p trÆ°á»›c Ä‘Ã³ nhÆ° BinaryConnect vÃ  BinaryNet tuy Ä‘áº¡t káº¿t quáº£ tá»‘t trÃªn cÃ¡c bá»™ dá»¯ liá»‡u nhá» (vÃ­ dá»¥: CIFAR-10, MNIST), nhÆ°ng láº¡i gáº·p pháº£i "ná»—i Ä‘au" lá»›n khi Ã¡p dá»¥ng trÃªn cÃ¡c bá»™ dá»¯ liá»‡u quy mÃ´ lá»›n vÃ  phá»©c táº¡p hÆ¡n:
* **Sá»¥t giáº£m Ä‘á»™ chÃ­nh xÃ¡c nghiÃªm trá»ng trÃªn ImageNet:** BÃ i bÃ¡o chá»‰ ra ráº±ng phÆ°Æ¡ng phÃ¡p cá»§a BinaryConnect "khÃ´ng thÃ nh cÃ´ng láº¯m trÃªn cÃ¡c bá»™ dá»¯ liá»‡u quy mÃ´ lá»›n (vÃ­ dá»¥: ImageNet)". Káº¿t quáº£ thá»±c nghiá»‡m cho tháº¥y Ä‘á»™ chÃ­nh xÃ¡c top-1 cá»§a cÃ¡c phÆ°Æ¡ng phÃ¡p nÃ y trÃªn AlexNet-ImageNet ráº¥t tháº¥p (BC: 35.4%, BNN: 27.9%), kÃ©m xa so vá»›i mÃ´ hÃ¬nh gá»‘c cÃ³ Ä‘á»™ chÃ­nh xÃ¡c Ä‘áº§y Ä‘á»§.
* **Máº¥t mÃ¡t thÃ´ng tin lá»›n do lÆ°á»£ng tá»­ hÃ³a thÃ´:** Viá»‡c lÆ°á»£ng tá»­ hÃ³a cÃ¡c giÃ¡ trá»‹ thá»±c thÃ nh {+1, -1} má»™t cÃ¡ch trá»±c tiáº¿p gÃ¢y ra sai sá»‘ lá»›n, lÃ m giáº£m kháº£ nÄƒng biá»ƒu diá»…n cá»§a mÃ´ hÃ¬nh. CÃ¡c phÆ°Æ¡ng phÃ¡p cÅ© chÆ°a cÃ³ má»™t cÆ¡ cháº¿ hiá»‡u quáº£ Ä‘á»ƒ bÃ¹ Ä‘áº¯p cho sá»± máº¥t mÃ¡t biÃªn Ä‘á»™ (magnitude) cá»§a cÃ¡c trá»ng sá»‘ vÃ  Ä‘áº§u vÃ o.

#### **3. ÄÃ³ng gÃ³p má»›i lÃ  gÃ¬? ğŸ’¡**

BÃ i bÃ¡o tuyÃªn bá»‘ ba Ä‘Ã³ng gÃ³p chÃ­nh, giáº£i quyáº¿t trá»±c tiáº¿p cÃ¡c Ä‘iá»ƒm yáº¿u trÃªn:

1.  **PhÆ°Æ¡ng phÃ¡p nhá»‹ phÃ¢n hÃ³a cÃ³ há»‡ sá»‘ tá»‰ lá»‡ (Scaled Binarization):** ÄÃ¢y lÃ  Ä‘Ã³ng gÃ³p cá»‘t lÃµi. Thay vÃ¬ xáº¥p xá»‰ má»™t trá»ng sá»‘ thá»±c $W$ Ä‘Æ¡n giáº£n báº±ng $sign(W)$, tÃ¡c giáº£ Ä‘á» xuáº¥t má»™t phÃ©p xáº¥p xá»‰ tá»‘t hÆ¡n: $W \approx \alpha B$, trong Ä‘Ã³ $B = sign(W)$ vÃ  $\alpha$ lÃ  má»™t há»‡ sá»‘ tá»‰ lá»‡ dÆ°Æ¡ng. Quan trá»ng hÆ¡n, há» Ä‘Ã£ chá»©ng minh vÃ  Ä‘Æ°a ra cÃ´ng thá»©c tÃ­nh giÃ¡ trá»‹ $\alpha$ tá»‘i Æ°u lÃ  trung bÃ¬nh cá»§a giÃ¡ trá»‹ tuyá»‡t Ä‘á»‘i cÃ¡c trá»ng sá»‘: $\alpha^* = \frac{1}{n}\|W\|_{l1}$. Viá»‡c nÃ y giÃºp báº£o toÃ n thÃ´ng tin vá» biÃªn Ä‘á»™ cá»§a bá»™ lá»c gá»‘c.
2.  **Kiáº¿n trÃºc XNOR-Net vá»›i khá»‘i tÃ­nh toÃ¡n Ä‘Æ°á»£c sáº¯p xáº¿p láº¡i:** Äá»‘i vá»›i XNOR-Net (nhá»‹ phÃ¢n hÃ³a cáº£ trá»ng sá»‘ vÃ  Ä‘áº§u vÃ o), cÃ¡c tÃ¡c giáº£ Ä‘á» xuáº¥t má»™t cáº¥u trÃºc khá»‘i tÃ­nh toÃ¡n má»›i. Thay vÃ¬ thá»© tá»± truyá»n thá»‘ng `Conv -> BatchNorm -> Activation -> Pool`, há» Ä‘á» xuáº¥t `BatchNorm -> Binary Activation -> Binary Conv -> Pool`. Viá»‡c chuáº©n hÃ³a (BatchNorm) *trÆ°á»›c khi* nhá»‹ phÃ¢n hÃ³a giÃºp giáº£m sai sá»‘ lÆ°á»£ng tá»­ hÃ³a má»™t cÃ¡ch Ä‘Ã¡ng ká»ƒ.
3.  **ÄÃ¡nh giÃ¡ toÃ n diá»‡n trÃªn ImageNet:** ÄÃ¢y lÃ  bÃ i bÃ¡o Ä‘áº§u tiÃªn trÃ¬nh bÃ y má»™t Ä‘Ã¡nh giÃ¡ chi tiáº¿t vÃ  thÃ nh cÃ´ng vá» máº¡ng nÆ¡-ron nhá»‹ phÃ¢n trÃªn bá»™ dá»¯ liá»‡u ImageNet quy mÃ´ lá»›n. Äiá»u nÃ y chá»©ng tá» tÃ­nh kháº£ thi cá»§a viá»‡c nhá»‹ phÃ¢n hÃ³a cho cÃ¡c tÃ¡c vá»¥ thá»‹ giÃ¡c mÃ¡y tÃ­nh phá»©c táº¡p trong thá»±c táº¿.

---

### **Pháº§n B: PhÃ¢n tÃ­ch Kiáº¿n trÃºc vÃ  ThÃ nh pháº§n má»›i**

#### **4. Cáº¥u trÃºc tá»•ng thá»ƒ**

MÃ´ hÃ¬nh Ä‘Æ°á»£c Ä‘á» xuáº¥t khÃ´ng pháº£i lÃ  má»™t kiáº¿n trÃºc hoÃ n toÃ n má»›i tá»« Ä‘áº§u, mÃ  lÃ  má»™t **phÆ°Æ¡ng phÃ¡p luáº­n Ä‘á»ƒ biáº¿n Ä‘á»•i cÃ¡c kiáº¿n trÃºc CNN tiÃªu chuáº©n** (nhÆ° AlexNet, ResNet) thÃ nh cÃ¡c phiÃªn báº£n nhá»‹ phÃ¢n hiá»‡u quáº£.

SÆ¡ Ä‘á»“ khá»‘i tá»•ng thá»ƒ cÃ³ thá»ƒ Ä‘Æ°á»£c mÃ´ táº£ nhÆ° sau:
1.  **Äáº§u vÃ o:** Má»™t áº£nh Ä‘áº§u vÃ o (vÃ­ dá»¥: kÃ­ch thÆ°á»›c 3x224x224).
2.  **Lá»›p tÃ­ch cháº­p Ä‘áº§u tiÃªn:** Giá»¯ nguyÃªn á»Ÿ Ä‘á»™ chÃ­nh xÃ¡c Ä‘áº§y Ä‘á»§ (full-precision). LÃ½ do lÃ  lá»›p nÃ y cÃ³ sá»‘ kÃªnh Ä‘áº§u vÃ o nhá» (c=3), nÃªn viá»‡c nhá»‹ phÃ¢n hÃ³a khÃ´ng mang láº¡i lá»£i Ã­ch lá»›n vá» tá»‘c Ä‘á»™ nhÆ°ng láº¡i áº£nh hÆ°á»Ÿng nhiá»u Ä‘áº¿n Ä‘á»™ chÃ­nh xÃ¡c.
3.  **CÃ¡c lá»›p tÃ­ch cháº­p á»Ÿ giá»¯a:** ÄÃ¢y lÃ  nÆ¡i Ã¡p dá»¥ng sá»± thay Ä‘á»•i. CÃ¡c khá»‘i tÃ­ch cháº­p tiÃªu chuáº©n Ä‘Æ°á»£c thay tháº¿ báº±ng má»™t trong hai loáº¡i khá»‘i má»›i:
    * **Khá»‘i Binary-Weight (BWN):** CÃ¡c trá»ng sá»‘ Ä‘Æ°á»£c nhá»‹ phÃ¢n hÃ³a, cÃ²n Ä‘áº§u vÃ o váº«n lÃ  giÃ¡ trá»‹ thá»±c. PhÃ©p tÃ­ch cháº­p Ä‘Æ°á»£c xáº¥p xá»‰ báº±ng phÃ©p cá»™ng/trá»«.
    * **Khá»‘i XNOR-Net:** Cáº£ trá»ng sá»‘ vÃ  Ä‘áº§u vÃ o Ä‘á»u Ä‘Æ°á»£c nhá»‹ phÃ¢n hÃ³a. Cáº¥u trÃºc khá»‘i Ä‘Æ°á»£c sáº¯p xáº¿p láº¡i nhÆ° Ä‘Ã£ mÃ´ táº£ á»Ÿ trÃªn.
4.  **Lá»›p tÃ­ch cháº­p cuá»‘i cÃ¹ng (thÆ°á»ng lÃ  lá»›p káº¿t ná»‘i Ä‘áº§y Ä‘á»§):** CÅ©ng Ä‘Æ°á»£c giá»¯ á»Ÿ Ä‘á»™ chÃ­nh xÃ¡c Ä‘áº§y Ä‘á»§, vÃ¬ kÃ­ch thÆ°á»›c bá»™ lá»c thÆ°á»ng lÃ  1x1, khÃ´ng Ä‘Æ°á»£c lá»£i nhiá»u tá»« viá»‡c nhá»‹ phÃ¢n hÃ³a.
5.  **Äáº§u ra:** Lá»›p softmax cho ra xÃ¡c suáº¥t phÃ¢n loáº¡i.

#### **5. CÃ¡c khá»‘i xÃ¢y dá»±ng (Building Blocks)**

MÃ´ hÃ¬nh Ä‘Æ°á»£c xÃ¢y dá»±ng tá»« cÃ¡c thÃ nh pháº§n chÃ­nh sau:
* **Lá»›p TÃ­ch cháº­p Nhá»‹ phÃ¢n Trá»ng sá»‘ (Binary-Weight Convolution):** LÃ  má»™t lá»›p tÃ­ch cháº­p thÃ´ng thÆ°á»ng nhÆ°ng phÃ©p nhÃ¢n ma tráº­n Ä‘Æ°á»£c thay tháº¿. Trá»ng sá»‘ $W$ Ä‘Æ°á»£c xáº¥p xá»‰ báº±ng $\alpha \cdot sign(W)$. PhÃ©p toÃ¡n $I * W$ Ä‘Æ°á»£c tÃ­nh báº±ng $(I \oplus B)\alpha$, trong Ä‘Ã³ $\oplus$ lÃ  phÃ©p tÃ­ch cháº­p chá»‰ dÃ¹ng phÃ©p cá»™ng/trá»«.
* **Khá»‘i XNOR-Net:** ÄÃ¢y lÃ  má»™t chuá»—i cÃ¡c lá»›p Ä‘Æ°á»£c sáº¯p xáº¿p theo má»™t thá»© tá»± cá»¥ thá»ƒ:
    1.  **Batch Normalization:** Chuáº©n hÃ³a Ä‘áº§u vÃ o.
    2.  **Binary Activation (BinActiv):** Má»™t lá»›p logic má»›i, tÃ­nh toÃ¡n $sign(I)$ vÃ  ma tráº­n há»‡ sá»‘ tá»‰ lá»‡ $K$ cho Ä‘áº§u vÃ o.
    3.  **Binary Convolution (BinConv):** Thá»±c hiá»‡n phÃ©p tÃ­ch cháº­p báº±ng XNOR vÃ  bitcount trÃªn cÃ¡c Ä‘áº§u vÃ o vÃ  trá»ng sá»‘ Ä‘Ã£ Ä‘Æ°á»£c nhá»‹ phÃ¢n hÃ³a, sau Ä‘Ã³ nhÃ¢n vá»›i cÃ¡c há»‡ sá»‘ tá»‰ lá»‡.
    4.  **Pooling:** Lá»›p gá»™p (vÃ­ dá»¥: Max Pooling).

#### **6. ThÃ nh pháº§n "Äƒn tiá»n" (Novel Component) âš™ï¸**

ThÃ nh pháº§n kiáº¿n trÃºc má»›i láº¡ vÃ  quan trá»ng nháº¥t chÃ­nh lÃ  **Khá»‘i XNOR-Net** vá»›i sá»± káº¿t há»£p cá»§a lá»›p **Binary Activation (BinActiv)** vÃ  thá»© tá»± sáº¯p xáº¿p cÃ¡c lá»›p.

**Cáº¥u táº¡o vÃ  cÃ¡ch hoáº¡t Ä‘á»™ng chi tiáº¿t:**
HÃ£y xem xÃ©t Ä‘áº§u vÃ o cá»§a khá»‘i nÃ y lÃ  má»™t tensor Ä‘áº·c trÆ°ng $I$ (real-valued) tá»« lá»›p trÆ°á»›c.
1.  **Batch Normalization:** $I$ Ä‘Æ°á»£c chuáº©n hÃ³a Ä‘á»ƒ cÃ³ trung bÃ¬nh gáº§n 0 vÃ  phÆ°Æ¡ng sai 1. Äiá»u nÃ y cá»±c ká»³ quan trá»ng vÃ¬ nÃ³ Ä‘áº£m báº£o dá»¯ liá»‡u phÃ¢n bá»‘ quanh ngÆ°á»¡ng 0, giÃºp hÃ m $sign(I)$ giá»¯ láº¡i nhiá»u thÃ´ng tin nháº¥t cÃ³ thá»ƒ.
2.  **Binary Activation (BinActiv):** Lá»›p nÃ y thá»±c hiá»‡n hai nhiá»‡m vá»¥ song song trÃªn Ä‘áº§u vÃ o $I$ Ä‘Ã£ Ä‘Æ°á»£c chuáº©n hÃ³a:
    * **Nhá»‹ phÃ¢n hÃ³a Ä‘áº§u vÃ o:** Táº¡o ra tensor nhá»‹ phÃ¢n $H = sign(I)$.
    * **TÃ­nh há»‡ sá»‘ tá»‰ lá»‡ cho Ä‘áº§u vÃ o:** Äá»ƒ bÃ¹ Ä‘áº¯p cho sá»± máº¥t mÃ¡t biÃªn Ä‘á»™ cá»§a $I$, má»™t ma tráº­n há»‡ sá»‘ tá»‰ lá»‡ $K$ Ä‘Æ°á»£c tÃ­nh toÃ¡n. QuÃ¡ trÃ¬nh nÃ y ráº¥t thÃ´ng minh Ä‘á»ƒ trÃ¡nh tÃ­nh toÃ¡n láº·p:
        * Äáº§u tiÃªn, tÃ­nh má»™t ma tráº­n $A$ báº±ng cÃ¡ch láº¥y trung bÃ¬nh giÃ¡ trá»‹ tuyá»‡t Ä‘á»‘i cá»§a $I$ trÃªn táº¥t cáº£ cÃ¡c kÃªnh.
        * Sau Ä‘Ã³, tÃ­ch cháº­p ma tráº­n $A$ nÃ y vá»›i má»™t bá»™ lá»c trung bÃ¬nh (vÃ­ dá»¥ 3x3, táº¥t cáº£ cÃ¡c giÃ¡ trá»‹ báº±ng 1/9) Ä‘á»ƒ táº¡o ra $K$. Má»—i pháº§n tá»­ trong $K$ Ä‘áº¡i diá»‡n cho há»‡ sá»‘ tá»‰ lá»‡ trung bÃ¬nh cá»§a má»™t vÃ¹ng tÆ°Æ¡ng á»©ng trong $I$.
3.  **Binary Convolution (BinConv):** Lá»›p nÃ y nháº­n Ä‘áº§u vÃ o lÃ  $H$ vÃ  $K$. NÃ³ cÅ©ng cÃ³ cÃ¡c trá»ng sá»‘ nhá»‹ phÃ¢n $B = sign(W)$ vÃ  há»‡ sá»‘ tá»‰ lá»‡ $\alpha$ cá»§a riÃªng nÃ³. PhÃ©p tÃ­ch cháº­p Ä‘Æ°á»£c xáº¥p xá»‰ bá»Ÿi cÃ´ng thá»©c:
    $$I * W \approx (sign(I) \otimes sign(W)) \odot K\alpha$$
    trong Ä‘Ã³ $\otimes$ lÃ  phÃ©p tÃ­ch cháº­p hiá»‡u quáº£ cao sá»­ dá»¥ng **XNOR vÃ  bit-counting** (Ä‘áº¿m bit), vÃ  $\odot$ lÃ  phÃ©p nhÃ¢n theo tá»«ng pháº§n tá»­ (element-wise).

Sá»± káº¿t há»£p nÃ y Ä‘áº£m báº£o cáº£ trá»ng sá»‘ vÃ  Ä‘áº§u vÃ o Ä‘á»u Ä‘Æ°á»£c xáº¥p xá»‰ má»™t cÃ¡ch tá»‘i Æ°u nháº¥t cÃ³ thá»ƒ trÆ°á»›c khi thá»±c hiá»‡n phÃ©p tÃ­ch cháº­p nhá»‹ phÃ¢n, giÃºp giáº£m thiá»ƒu sai sá»‘ vÃ  cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ Ä‘á»™ chÃ­nh xÃ¡c.

---

### **Pháº§n C: Quy trÃ¬nh hoáº¡t Ä‘á»™ng (Pipeline)**

#### **7. Pipeline Huáº¥n luyá»‡n (Training Pipeline)**

Quy trÃ¬nh huáº¥n luyá»‡n Ä‘Æ°á»£c mÃ´ táº£ trong **Thuáº­t toÃ¡n 1** vÃ  cÃ³ má»™t Ä‘iá»ƒm Ä‘áº·c biá»‡t quan trá»ng: luÃ´n duy trÃ¬ má»™t báº£n sao cá»§a cÃ¡c trá»ng sá»‘ á»Ÿ dáº¡ng sá»‘ thá»±c (real-valued) Ä‘á»ƒ cáº­p nháº­t.

* **Input:** Má»™t minibatch gá»“m cÃ¡c áº£nh vÃ  nhÃ£n tÆ°Æ¡ng á»©ng $(I, Y)$.
* **Step 1: Tiá»n xá»­ lÃ½ dá»¯ liá»‡u:** áº¢nh Ä‘Æ°á»£c thay Ä‘á»•i kÃ­ch thÆ°á»›c vÃ  cáº¯t ngáº«u nhiÃªn (random crop) thÃ nh kÃ­ch thÆ°á»›c cá»‘ Ä‘á»‹nh, vÃ­ dá»¥ 224x224, Ä‘á»ƒ tÄƒng tÃ­nh Ä‘a dáº¡ng cá»§a dá»¯ liá»‡u.
* **Step 2: Dá»¯ liá»‡u Ä‘i qua mÃ´ hÃ¬nh (Forward Pass):**
    1.  Äá»‘i vá»›i má»—i lá»›p tÃ­ch cháº­p, tá»« cÃ¡c trá»ng sá»‘ thá»±c Ä‘ang Ä‘Æ°á»£c lÆ°u trá»¯ $\mathcal{W}^t$, tÃ­nh toÃ¡n cÃ¡c trá»ng sá»‘ nhá»‹ phÃ¢n $\mathcal{B}_{lk} = sign(\mathcal{W}_{lk}^t)$ vÃ  há»‡ sá»‘ tá»‰ lá»‡ $\mathcal{A}_{lk} = \frac{1}{n}||\mathcal{W}_{lk}^{t}||_{l1}$.
    2.  XÃ¢y dá»±ng trá»ng sá»‘ xáº¥p xá»‰ cho lÆ°á»£t truyá»n nÃ y: $\tilde{\mathcal{W}}_{lk} = \mathcal{A}_{lk}\mathcal{B}_{lk}$.
    3.  Thá»±c hiá»‡n lan truyá»n xuÃ´i báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c trá»ng sá»‘ xáº¥p xá»‰ $\tilde{\mathcal{W}}$ (vÃ  Ä‘áº§u vÃ o nhá»‹ phÃ¢n hÃ³a tÆ°Æ¡ng á»©ng cho XNOR-Net) Ä‘á»ƒ tÃ­nh toÃ¡n Ä‘áº§u ra $\hat{Y}$.
* **Step 3: TÃ­nh toÃ¡n HÃ m máº¥t mÃ¡t vÃ  Lan truyá»n ngÆ°á»£c (Backward Pass):**
    1.  HÃ m máº¥t mÃ¡t $C(Y, \hat{Y})$ Ä‘Æ°á»£c tÃ­nh (vÃ­ dá»¥: negative-log-likelihood).
    2.  Gradient Ä‘Æ°á»£c tÃ­nh toÃ¡n vÃ  lan truyá»n ngÆ°á»£c. ÄÃ¡ng chÃº Ã½, gradient Ä‘Æ°á»£c tÃ­nh dá»±a trÃªn cÃ¡c trá»ng sá»‘ xáº¥p xá»‰ $\tilde{\mathcal{W}}$.
* **Step 4: Cáº­p nháº­t Trá»ng sá»‘:**
    1.  Gradient tÃ­nh Ä‘Æ°á»£c á»Ÿ bÆ°á»›c trÃªn Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ **cáº­p nháº­t báº£n sao trá»ng sá»‘ thá»±c $\mathcal{W}^t$** báº±ng má»™t bá»™ tá»‘i Æ°u nhÆ° SGD hoáº·c ADAM.
    2.  Viá»‡c cáº­p nháº­t trá»ng sá»‘ thá»±c nÃ y cho phÃ©p tÃ­ch lÅ©y nhá»¯ng thay Ä‘á»•i nhá» tá»« gradient, Ä‘iá»u mÃ  sáº½ bá»‹ máº¥t náº¿u cáº­p nháº­t trá»±c tiáº¿p lÃªn trá»ng sá»‘ nhá»‹ phÃ¢n.
* **Output:** Bá»™ trá»ng sá»‘ thá»±c Ä‘Ã£ Ä‘Æ°á»£c cáº­p nháº­t $\mathcal{W}^{t+1}$.

#### **8. Pipeline Suy luáº­n (Inference Pipeline)**

Quy trÃ¬nh suy luáº­n Ä‘Æ¡n giáº£n vÃ  hiá»‡u quáº£ hÆ¡n ráº¥t nhiá»u so vá»›i huáº¥n luyá»‡n.

* **Input:** Má»™t áº£nh má»›i cáº§n dá»± Ä‘oÃ¡n.
* **Quy trÃ¬nh:**
    1.  **KhÃ´ng cáº§n trá»ng sá»‘ thá»±c:** Sau khi huáº¥n luyá»‡n káº¿t thÃºc, báº£n sao trá»ng sá»‘ thá»±c cÃ³ thá»ƒ Ä‘Æ°á»£c loáº¡i bá» hoÃ n toÃ n. MÃ´ hÃ¬nh cuá»‘i cÃ¹ng chá»‰ lÆ°u trá»¯ cÃ¡c trá»ng sá»‘ nhá»‹ phÃ¢n $B$ vÃ  cÃ¡c há»‡ sá»‘ tá»‰ lá»‡ $\alpha$ tÆ°Æ¡ng á»©ng.
    2.  **Tiá»n xá»­ lÃ½:** áº¢nh thÆ°á»ng Ä‘Æ°á»£c xá»­ lÃ½ Ä‘Æ¡n giáº£n hÆ¡n, vÃ­ dá»¥ nhÆ° chá»‰ láº¥y má»™t vÃ¹ng cáº¯t á»Ÿ trung tÃ¢m (center crop).
    3.  **Lan truyá»n xuÃ´i:** áº¢nh Ä‘Æ°á»£c Ä‘Æ°a qua máº¡ng. Táº¥t cáº£ cÃ¡c phÃ©p tÃ­ch cháº­p Ä‘á»u Ä‘Æ°á»£c thá»±c hiá»‡n báº±ng cÃ¡c phÃ©p toÃ¡n nhá»‹ phÃ¢n hiá»‡u quáº£ cao (cá»™ng/trá»« cho BWN, XNOR-bitcount cho XNOR-Net). KhÃ´ng cÃ³ lan truyá»n ngÆ°á»£c hay cáº­p nháº­t trá»ng sá»‘.
* **KhÃ¡c biá»‡t so vá»›i lÃºc huáº¥n luyá»‡n:**
    * **Trá»ng sá»‘:** Sá»­ dá»¥ng trá»ng sá»‘ nhá»‹ phÃ¢n cá»‘ Ä‘á»‹nh, khÃ´ng cÃ²n báº£n sao trá»ng sá»‘ thá»±c.
    * **Tá»‘c Ä‘á»™:** Nhanh hÆ¡n ráº¥t nhiá»u (lÃªn tá»›i 58x) do sá»­ dá»¥ng cÃ¡c phÃ©p toÃ¡n bitwise thay vÃ¬ phÃ©p nhÃ¢n sá»‘ thá»±c.
    * **Bá»™ nhá»›:** YÃªu cáº§u bá»™ nhá»› Ã­t hÆ¡n ~32 láº§n Ä‘á»ƒ lÆ°u trá»¯ mÃ´ hÃ¬nh.
    * **TÃ­nh toÃ¡n:** KhÃ´ng cÃ³ bÆ°á»›c lan truyá»n ngÆ°á»£c vÃ  cáº­p nháº­t tham sá»‘.
    * **Dropout/Augmentation:** CÃ¡c ká»¹ thuáº­t nhÆ° Dropout (náº¿u cÃ³) vÃ  data augmentation Ä‘á»u bá»‹ vÃ´ hiá»‡u hÃ³a.